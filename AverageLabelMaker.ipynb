{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "MAX_VERSES = 199\n",
    "#annotation_list = [\"Copy of ENGESV_Romans_segments - English1.tsv\", \"Copy of ENGESV_Romans_segments - English2.tsv\", \"Copy of ENGESV_Romans_segments - English3.tsv\", \"Copy of ENGESV_Romans_segments - chinese1.tsv\", \"Copy of ENGESV_Romans_segments - chinese2_run.tsv\", \"Copy of ENGESV_Romans_segments - chinese3_Lin.tsv\"]\n",
    "annotation_list = []\n",
    "annotation_list.append(\"Copy of ENGESV_Romans_segments - Romanian_David.tsv\")\n",
    "annotation_list.append(\"Copy of ENGESV_Romans_segments - Korean_Kathleen.tsv\")\n",
    "annotation_list.append(\"Copy of ENGESV_Romans_segments - Dutch_Huyen.tsv\")\n",
    "annotation_list.append(\"Copy of ENGESV_Romans_segments - Vietnamese_Huyen.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer the contents of a tsv file to a list for easier access\n",
    "def tsv_to_list(annotation_file, max_verses):\n",
    "    annotation_list = [] # rows are verses, columns are title, text, labels\n",
    "    annotation = open(annotation_file)\n",
    "    read_tsv = csv.reader(annotation, delimiter=\"\\t\") \n",
    "    verse_count = 1\n",
    "    for row in read_tsv:\n",
    "        if verse_count == max_verses:\n",
    "            break\n",
    "        annotation_list.append(row)\n",
    "        verse_count += 1\n",
    "    return annotation_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_for(annotation):\n",
    "    labels = []\n",
    "    for row in annotation:\n",
    "        if row[5] == '?' or row[5] == 'X': # don't use unsure\n",
    "            labels.append(None)\n",
    "        elif row[2].upper() == 'X' and (row[3].upper() != 'X' and row[4].upper() == 'X'): # don't use pos + neg mixed labels\n",
    "            labels.append(None) \n",
    "        elif row[2].upper() == 'X' and (row[3].upper() != 'X' and row[4].upper() != 'X'): # only pos\n",
    "            labels.append(1)\n",
    "        elif row[2].upper() == 'X' and (row[3].upper() == 'X' and row[4].upper() != 'X'): # pos + neu\n",
    "            labels.append(0.5)\n",
    "        elif row[3].upper() == 'X' and (row[2].upper() != 'X' and row[4].upper() != 'X'): # only neu \n",
    "            labels.append(0)\n",
    "        elif row[4].upper() == 'X' and (row[3].upper() != 'X' and row[2].upper() != 'X'): # only neg\n",
    "            labels.append(-1)\n",
    "        elif row[4].upper() == 'X' and (row[3].upper() == 'X' and row[2].upper() != 'X'): # neg + neu\n",
    "            labels.append(-0.5)       \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor annotation in annotations:\\n    verse_count = 0\\n    while verse_count < len(annotations[0]):\\n        if annotation[verse_count] == None:\\n            for annot in annotations:\\n                del annot[verse_count]\\n        else:\\n            verse_count += 1\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "english1 = tsv_to_list(annotation_list[0], MAX_VERSES)\n",
    "english2 = tsv_to_list(annotation_list[1], MAX_VERSES)\n",
    "english3 = tsv_to_list(annotation_list[2], MAX_VERSES)\n",
    "chinese1 = tsv_to_list(annotation_list[3], MAX_VERSES)\n",
    "chinese2 = tsv_to_list(annotation_list[4], MAX_VERSES)\n",
    "chinese3 = tsv_to_list(annotation_list[5], MAX_VERSES)\n",
    "\n",
    "english1_labels = get_labels_for(english1)\n",
    "english2_labels = get_labels_for(english2)\n",
    "english3_labels = get_labels_for(english3)\n",
    "chinese1_labels = get_labels_for(chinese1)\n",
    "chinese2_labels = get_labels_for(chinese2)\n",
    "chinese3_labels = get_labels_for(chinese3)\n",
    "\n",
    "annotations = []\n",
    "annotations.append(english1_labels) \n",
    "annotations.append(english2_labels)\n",
    "annotations.append(english3_labels)\n",
    "annotations.append(chinese1_labels)\n",
    "annotations.append(chinese2_labels) \n",
    "annotations.append(chinese3_labels) \n",
    "\n",
    "\n",
    "for annotation in annotations:\n",
    "    verse_count = 0\n",
    "    while verse_count < len(annotations[0]):\n",
    "        if annotation[verse_count] == None:\n",
    "            for annot in annotations:\n",
    "                del annot[verse_count]\n",
    "        else:\n",
    "            verse_count += 1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "romanian = tsv_to_list(annotation_list[2], MAX_VERSES)\n",
    "romanian_labels = get_labels_for(romanian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198\n"
     ]
    }
   ],
   "source": [
    "print(len(romanian_labels))\n",
    "import csv\n",
    "avg_file = open(\"RomanianAverageLabels\", 'w')\n",
    "for verse_count in range(len(romanian_labels)):\n",
    "    write = str(romanian_labels[verse_count])+\"\\n\"\n",
    "    avg_file.write(write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_speech_labels_for(annotation_file):\n",
    "    labels = []\n",
    "    annotation_list = []\n",
    "    annotation = open(annotation_file)\n",
    "    read_tsv = csv.reader(annotation, delimiter=\"\\t\") \n",
    "    verse_count = 1\n",
    "    for row in read_tsv:\n",
    "        if verse_count == MAX_VERSES:\n",
    "            break\n",
    "        annotation_list.append(row)\n",
    "        verse_count += 1\n",
    "    \n",
    "    for row in annotation_list:\n",
    "        if '?' in row[6] or row[6] == '': # don't use unsure\n",
    "            labels.append(None)\n",
    "        elif row[6].upper() == 'P': # only pos\n",
    "            labels.append(1)\n",
    "        elif row[6].upper() == 'NU' or row[6].upper() == 'NE': # only neu \n",
    "            labels.append(0)\n",
    "        elif row[6].upper() == 'N' or row[6].upper() == 'NG': # only neg\n",
    "            labels.append(-1)\n",
    "        else:\n",
    "            if 'P' in row[6].upper() and ('NU' in row[6].upper() or 'NE' in row[6].upper()): # pos + neu\n",
    "                labels.append(0.5)\n",
    "            elif ('N' in row[6].upper() or 'NG' in row[6].upper()) and ('NU' in row[6].upper() or 'NE' in row[6].upper()): # neg + neu\n",
    "                labels.append(-0.5)\n",
    "            else: # pos + neg mixed\n",
    "                labels.append(None)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the text sentiment for a single verse from a tsv file\n",
    "# Numerical range (-3 is unsure, -2 is pos+neg)\n",
    "def get_text_sentiment_for_verse(verse_num, tsv_file):\n",
    "    annotations = open(tsv_file)\n",
    "    read_tsv = csv.reader(annotations, delimiter=\"\\t\")\n",
    "    row_count = 0\n",
    "    for row in read_tsv:\n",
    "        if row_count == verse_num:\n",
    "            if row[5] == '?' or row[5] == 'X': # unsure\n",
    "                return -3\n",
    "            elif row[2].upper() == 'X' and (row[3].upper() != 'X' and row[4].upper() == 'X'): # pos + neg mixed labels\n",
    "                return -2 \n",
    "            elif row[2].upper() == 'X' and (row[3].upper() != 'X' and row[4].upper() != 'X'): # only pos\n",
    "                return 1\n",
    "            elif row[2].upper() == 'X' and (row[3].upper() == 'X' and row[4].upper() != 'X'): # pos + neu\n",
    "                return 0.5\n",
    "            elif row[3].upper() == 'X' and (row[2].upper() != 'X' and row[4].upper() != 'X'): # only neu \n",
    "                return 0\n",
    "            elif row[4].upper() == 'X' and (row[3].upper() != 'X' and row[2].upper() != 'X'): # only neg\n",
    "                return -1\n",
    "            elif row[4].upper() == 'X' and (row[3].upper() == 'X' and row[2].upper() != 'X'): # neg + neu\n",
    "                return -0.5  \n",
    "            else:\n",
    "                print(\"outlier row:\", row_count)\n",
    "                return -3\n",
    "        row_count += 1\n",
    "    annotations.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_speech_labels_for(annotation_file):\n",
    "    labels = []\n",
    "    annotation_list = []\n",
    "    annotation = open(annotation_file)\n",
    "    read_tsv = csv.reader(annotation, delimiter=\"\\t\") \n",
    "    row_count = 0\n",
    "    for row in read_tsv:\n",
    "        if row_count == MAX_VERSES:\n",
    "            break\n",
    "        if len(row) > 9:\n",
    "            if row[9] == '?' or row[9].upper() == 'X': # don't use unsure\n",
    "                labels.append(None)\n",
    "                #print(\">9, unsure\", row_count)\n",
    "                row_count += 1\n",
    "                continue\n",
    "            elif row[6] == '' and row[7] == '' and row[8] == '':\n",
    "                sentiment = get_text_sentiment_for_verse(row_count, annotation_file)\n",
    "                #print(\">9, sentiment\", sentiment, row_count)\n",
    "                if sentiment == -2 or sentiment == -3: labels.append(None)\n",
    "                else: labels.append(sentiment)\n",
    "        if row[6].upper() == 'X' and (row[7].upper() != 'X' and row[8].upper() == 'X'): # pos + neg labels\n",
    "            labels.append(None) \n",
    "            #print(\"unsure\", row_count)\n",
    "        elif row[6].upper() == 'X' and (row[7].upper() != 'X' and row[8].upper() != 'X'): # only pos\n",
    "            labels.append(1) \n",
    "            #print(\"pos\", row_count)\n",
    "        elif row[6].upper() == 'X' and (row[7].upper() == 'X' and row[8].upper() != 'X'): # pos + neu\n",
    "            labels.append(0.5)\n",
    "            #print(\"0.5\", row_count)\n",
    "        elif row[7].upper() == 'X' and (row[6].upper() != 'X' and row[8].upper() != 'X'): # only neu \n",
    "            labels.append(0) \n",
    "            #print(\"neu\", row_count)\n",
    "        elif row[8].upper() == 'X' and (row[7].upper() != 'X' and row[6].upper() != 'X'): # only neg\n",
    "            labels.append(-1) \n",
    "            #print(\"neg\", row_count)\n",
    "        elif row[8].upper() == 'X' and (row[7].upper() == 'X' and row[6].upper() != 'X'): # neg + neu\n",
    "            labels.append(-0.5)\n",
    "            #print(\"-0.5\", row_count)\n",
    "        elif row[6] == '' and row[7] == '' and row[8] == '' and len(row) <= 9:\n",
    "            sentiment = get_text_sentiment_for_verse(row_count, annotation_file)\n",
    "            #print(\"sentiment\", sentiment, row_count)\n",
    "            if sentiment == -2 or sentiment == -3: labels.append(None)\n",
    "            else: labels.append(sentiment)\n",
    "        else:\n",
    "            if len(row) <= 9:\n",
    "                print(\"outlier row:\", row_count)\n",
    "                #print(\"outlier\", row_count)\n",
    "                labels.append(None)\n",
    "        row_count += 1\n",
    "    annotation.close()\n",
    "    \n",
    "    print(len(labels))\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198\n",
      "198\n"
     ]
    }
   ],
   "source": [
    "# use get_new_speech_labels_for method if the annotation was done with the new method of speech annotation\n",
    "labels = get_new_speech_labels_for(annotation_list[3])\n",
    "print(len(labels))\n",
    "import csv\n",
    "avg_file = open(\"RomanianAverageLabels\", 'w')\n",
    "for verse_count in range(len(labels)):\n",
    "    write = str(labels[verse_count])+\"\\n\"\n",
    "    avg_file.write(write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor annotation in speech_annotations:\\n    verse_count = 0\\n    while verse_count < len(speech_annotations[0]):\\n        if annotation[verse_count] == None:\\n            for annot in speech_annotations:\\n                del annot[verse_count]\\n        else:\\n            verse_count += 1\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "english1_labels = get_speech_labels_for(annotation_list[0])\n",
    "english2_labels = get_speech_labels_for(annotation_list[1])\n",
    "english3_labels = get_speech_labels_for(annotation_list[2])\n",
    "chinese1_labels = get_speech_labels_for(annotation_list[3])\n",
    "chinese2_labels = get_speech_labels_for(annotation_list[4])\n",
    "chinese3_labels = get_speech_labels_for(annotation_list[5])\n",
    "\n",
    "speech_annotations = []\n",
    "speech_annotations.append(english1_labels) \n",
    "speech_annotations.append(english2_labels) \n",
    "speech_annotations.append(english3_labels) \n",
    "speech_annotations.append(chinese1_labels)\n",
    "speech_annotations.append(chinese2_labels)\n",
    "speech_annotations.append(chinese3_labels) \n",
    "\n",
    "\n",
    "for annotation in speech_annotations:\n",
    "    verse_count = 0\n",
    "    while verse_count < len(speech_annotations[0]):\n",
    "        if annotation[verse_count] == None:\n",
    "            for annot in speech_annotations:\n",
    "                del annot[verse_count]\n",
    "        else:\n",
    "            verse_count += 1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, -1.0, 0.75, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.8333333333333334, 0.3333333333333333, -1.0, -1.0, -1.0, 0.0, 0.6666666666666666, -1.0, -0.6666666666666666, 1.0, 0.3333333333333333, -0.6666666666666666, 1.0, 1.0, 1.0, 0.3333333333333333, -0.5, 1.0, 1.0, 1.0, -0.6666666666666666, -1.0, -1.0, -1.0, 0.0, 0.6666666666666666, -1.0, -0.16666666666666666, 1.0, 0.0, 1.0, -0.6666666666666666, 1.0, -0.3333333333333333, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.5, 1.0, -0.3333333333333333, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 1.0, 1.0, 0.0, 0.0, 0.8333333333333334, 0.6666666666666666, 1.0, -1.0, -0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, -0.5, -0.5, -1.0, 0.5, 1.0, 1.0, None, None, 1.0, 1.0, 0.6666666666666666, 1.0, -1.0, 0.6666666666666666, 0.0, None, -1.0, -1.0, 0.3333333333333333, 1.0, 1.0, -0.3333333333333333, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -0.3333333333333333, 1.0, -1.0, None, 0.25, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, -0.3333333333333333, 0.75, -1.0, 0.0, 1.0, -0.6666666666666666, 0.0, -1.0] 198 \n",
      "\n",
      "[0.0, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.8333333333333334, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, -0.3333333333333333, 0.0, 1.0, 1.0, -1.0, 0.3333333333333333, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.6666666666666666, -1.0, -1.0, -0.6666666666666666, 0.0, 0.6666666666666666, -1.0, -0.6666666666666666, 0.6666666666666666, 0.6666666666666666, -0.3333333333333333, -0.3333333333333333, 0.0, 0.3333333333333333, 0.0, -0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 1.0, -0.6666666666666666, -1.0, -1.0, -1.0, -0.8333333333333334, -0.3333333333333333, -0.5, -0.3333333333333333, 0.6666666666666666, -0.3333333333333333, 0.0, -0.6666666666666666, 0.5, 0.0, -0.5, -1.0, -1.0, -1.0, -0.5, -0.3333333333333333, -1.0, -1.0, -1.0, -0.6666666666666666, -0.6666666666666666, -0.6666666666666666, -1.0, -0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.5, 0.0, 0.3333333333333333, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, -1.0, -1.0, 0.0, 1.0, 1.0, 0.16666666666666666, 0.6666666666666666, 1.0, 0.3333333333333333, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 0.8333333333333334, 0.3333333333333333, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 0.0, 0.5, 1.0, -0.5, -0.3333333333333333, -0.3333333333333333, 0.0, -0.16666666666666666, -1.0, 0.0, 0.0, 0.0, 0.5, 0.16666666666666666, 0.3333333333333333, -0.3333333333333333, 0.6666666666666666, 0.0, 0.5, -0.8333333333333334, -0.3333333333333333, -0.16666666666666666, 0.8333333333333334, 1.0, 0.0, 0.16666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, -0.6666666666666666, -0.3333333333333333, -0.6666666666666666, 0.0, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.5, 1.0, 0.3333333333333333, -0.16666666666666666, 0.3333333333333333, -1.0, -1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, -0.3333333333333333, 0.3333333333333333, 0.0, -0.25, -0.8333333333333334, 0.8333333333333334, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, -0.5, 0.75, -0.5, 0.0, 1.0, 0.0, 0.0, -1.0] 198\n"
     ]
    }
   ],
   "source": [
    "#speech averages\n",
    "\n",
    "label_total = 0\n",
    "annotator_count = 0\n",
    "avg_english_splabels = []\n",
    "avg_chinese_splabels = []\n",
    "\n",
    "english = [speech_annotations[0], speech_annotations[1], speech_annotations[2]]\n",
    "chinese = [speech_annotations[3], speech_annotations[4], speech_annotations[5]]\n",
    "for l in range(len(speech_annotations[0])):\n",
    "    for i in range(len(english)):\n",
    "        if english[i][l] != None:\n",
    "            label_total += english[i][l]\n",
    "            annotator_count += 1\n",
    "    if annotator_count == 0:\n",
    "        avg_english_splabels.append(None)\n",
    "    else:\n",
    "        avg_english_splabels.append(label_total / annotator_count)\n",
    "    annotator_count = 0\n",
    "    label_total = 0\n",
    "print(avg_english_splabels, len(avg_english_splabels), '\\n')\n",
    "\n",
    "label_total = 0\n",
    "annotator_count = 0\n",
    "for l in range(len(speech_annotations[3])):\n",
    "    for i in range(len(chinese)):\n",
    "        if chinese[i][l] != None:\n",
    "            label_total += chinese[i][l]\n",
    "            annotator_count += 1\n",
    "    if annotator_count == 0:\n",
    "        avg_chinese_splabels.append(None)\n",
    "    else:\n",
    "        avg_chinese_splabels.append(label_total / annotator_count)\n",
    "    label_total = 0\n",
    "    annotator_count = 0\n",
    "print(avg_chinese_splabels, len(avg_chinese_splabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text averages\n",
    "\n",
    "label_total = 0\n",
    "avg_english_labels = []\n",
    "avg_chinese_labels = []\n",
    "annotator_count = 0\n",
    "\n",
    "english = [annotations[0], annotations[1], annotations[2]]\n",
    "chinese = [annotations[3], annotations[4], annotations[5]]\n",
    "for l in range(len(annotations[0])):\n",
    "    for i in range(len(english)):\n",
    "        if english[i][l] != None:\n",
    "            label_total += english[i][l]\n",
    "            annotator_count += 1\n",
    "    if annotator_count == 0:\n",
    "        avg_english_labels.append(None)\n",
    "    else:\n",
    "        avg_english_labels.append(label_total / annotator_count)\n",
    "    label_total = 0\n",
    "    annotator_count = 0\n",
    "\n",
    "label_total = 0\n",
    "annotator_count = 0\n",
    "for l in range(len(annotations[3])):\n",
    "    for i in range(len(chinese)):\n",
    "        if chinese[i][l] != None:\n",
    "            label_total += chinese[i][l]\n",
    "            annotator_count += 1\n",
    "    if annotator_count == 0:\n",
    "        avg_chinese_labels.append(None)\n",
    "    else:\n",
    "        avg_chinese_labels.append(label_total / annotator_count)\n",
    "    label_total = 0\n",
    "    annotator_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198\n"
     ]
    }
   ],
   "source": [
    "print(len(avg_english_labels))\n",
    "import csv\n",
    "english_avg_file = open(\"C:/Users/shery/JupyterProjects/ChineseAverageLabels\", 'a')\n",
    "#out_file = csv.writer(chinese_avg_file, delimiter=\"\\t\") \n",
    "for verse_count in range(len(avg_english_labels)):\n",
    "    write = str(avg_english_labels[verse_count])+\"\\n\"\n",
    "    english_avg_file.write(write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
